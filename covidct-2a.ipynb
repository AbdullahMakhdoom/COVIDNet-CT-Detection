{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# importing necessary libraries\nimport os\nimport time\nimport copy\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch,torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, models, transforms\nimport torch.optim as optim\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\n\nfrom collections.abc import Iterable\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:12:20.979913Z","iopub.execute_input":"2022-04-26T19:12:20.980231Z","iopub.status.idle":"2022-04-26T19:12:20.986346Z","shell.execute_reply.started":"2022-04-26T19:12:20.980201Z","shell.execute_reply":"2022-04-26T19:12:20.985381Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def set_freeze_by_idxs(model, idxs, freeze=True): \n    \"\"\" Function to freeze layers of model during fine-training\"\"\"\n    if not isinstance(idxs, Iterable):\n        idxs = [idxs]\n    num_child = len(list(model.children()))\n    idxs = tuple(map(lambda idx: num_child + idx if idx < 0 else idx, idxs))\n    for idx, child in enumerate(model.children()):\n        if idx not in idxs:\n            continue\n        for param in child.parameters():\n            param.requires_grad = not freeze\n    return model\n            \ndef freeze_by_idxs(model, idxs):\n    return set_freeze_by_idxs(model, idxs, True)\n\ndef unfreeze_by_idxs(model, idxs):\n    return set_freeze_by_idxs(model, idxs, False)\n\ndef set_parameter_requires_grad(model):\n    for param in model.parameters():\n        param.requires_grad=False\n    return model\n\ndef initialize_model(model_name, num_classes, use_pretrained, unfreeze_num):\n    \"\"\"Function to intialize various model ['vgg16','vgg19','resnet101','resnet152','densenet161','densenet201']\n        and modify output classifier layers according to number of classes, with \"unfreeze_num\" of layers freezed.\n    \"\"\"\n    if model_name=='vgg16':\n        model_pre=models.vgg16(pretrained=use_pretrained) \n        model_pre.features[0].in_channels=1\n        model_pre.features[0].weight=Parameter(model_pre.features[0].weight[:,1:2,:,:])\n        model_pre=set_parameter_requires_grad(model_pre) \n        num_ftrs=model_pre.classifier[6].in_features # feature_map \n        model_pre.classifier[6]=nn.Linear(num_ftrs,num_classes) \n        if unfreeze_num==1:\n            unfreeze=[-1]\n        elif unfreeze_num==2:\n            unfreeze=[-1,-3]\n        elif unfreeze_num==3:\n            unfreeze=[-1,-3,-5]\n        else:\n            unfreeze=[-1,-3,-5,-7]\n        model_pre.features=unfreeze_by_idxs(model_pre.features,unfreeze)\n        for param in model_pre.classifier.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='vgg19':\n        model_pre=models.vgg19(pretrained=use_pretrained) \n        model_pre.features[0].in_channels=1\n        model_pre.features[0].weight=Parameter(model_pre.features[0].weight[:,1:2,:,:])\n        model_pre=set_parameter_requires_grad(model_pre) \n        num_ftrs=model_pre.classifier[6].in_features\n        model_pre.classifier[6]=nn.Linear(num_ftrs,num_classes) \n        if unfreeze_num==1:\n            unfreeze=[-1]\n        elif unfreeze_num==2:\n            unfreeze=[-1,-3]\n        elif unfreeze_num==3:\n            unfreeze=[-1,-3,-5]\n        else:\n            unfreeze=[-1,-3,-5,-7]\n        model_pre.features=unfreeze_by_idxs(model_pre.features,unfreeze)\n        for param in model_pre.classifier.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='resnet101':\n        model_pre=models.resnet101(pretrained=use_pretrained) \n        model_pre.conv1.in_channels=1\n        model_pre.conv1.weight=Parameter(model_pre.conv1.weight[:,1:2,:,:])\n        model_pre=set_parameter_requires_grad(model_pre)\n        num_ftrs=model_pre.fc.in_features \n        model_pre.fc=nn.Linear(num_ftrs,num_classes)\n        \n        for i in range(unfreeze_num):\n            model_pre.layer4=unfreeze_by_idxs(model_pre.layer4,-i)\n        for param in model_pre.fc.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='resnet152':\n        model_pre=models.resnet152(pretrained=use_pretrained) \n        model_pre.conv1.in_channels=1\n        model_pre.conv1.weight=Parameter(model_pre.conv1.weight[:,1:2,:,:])\n        model_pre=set_parameter_requires_grad(model_pre)\n        num_ftrs=model_pre.fc.in_features\n        model_pre.fc=nn.Linear(num_ftrs,num_classes)\n\n        for i in range(unfreeze_num):\n            model_pre.layer4=unfreeze_by_idxs(model_pre.layer4,-i)\n        for param in model_pre.fc.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='densenet161':\n        model_pre=models.densenet161(pretrained=use_pretrained)\n        model_pre.features[0].in_channels=1\n        model_pre.features[0].weight=Parameter(model_pre.features[0].weight[:,1:2,:,:])\n        model_pre=set_parameter_requires_grad(model_pre)\n        num_ftrs=model_pre.classifier.in_features \n        model_pre.classifier=nn.Linear(num_ftrs,num_classes)\n        \n        for i in range(unfreeze_num):\n            model_pre.features.denseblock4=unfreeze_by_idxs(model_pre.features.denseblock4,-i)\n        for param in model_pre.classifier.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='densenet201':\n        model_pre=models.densenet201(pretrained=use_pretrained)\n        model_pre.features[0].in_channels=1\n        model_pre.features[0].weight=Parameter(model_pre.features[0].weight[:,1:2,:,:])\n        model_pre=set_parameter_requires_grad(model_pre)\n        num_ftrs=model_pre.classifier.in_features \n        model_pre.classifier=nn.Linear(num_ftrs,num_classes)\n        for i in range(unfreeze_num):\n            model_pre.features.denseblock4=unfreeze_by_idxs(model_pre.features.denseblock4,-i)\n        for param in model_pre.classifier.parameters():\n            param.requires_grad=True\n        input_size=224\n    else:\n        print('model not implemented')\n        return None,None\n    return model_pre, input_size","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:12:38.842354Z","iopub.execute_input":"2022-04-26T19:12:38.842697Z","iopub.status.idle":"2022-04-26T19:12:38.869434Z","shell.execute_reply.started":"2022-04-26T19:12:38.842664Z","shell.execute_reply":"2022-04-26T19:12:38.868484Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model_all = []\ndir = '.'\n\ndef auto_net(model_name, num_classes, use_pretrained, unfreeze_num):\n    \"\"\" Function to prepare model using \"initialize_model\" method and saving the models with weights.\n        saved_model weights will be saved at '/{model_name}/{model_name}_{unfeeze_num}.pth'.\n        These weights could be loaded using torch.load(path) function.\"\"\"\n    model_all = []\n    for k in range(unfreeze_num):\n        model, input_size = initialize_model(model_name, num_classes, use_pretrained, k+1)\n        my_path = Path(dir + '/{}'.format(model_name))\n        if not my_path.is_dir():    \n            os.mkdir(my_path)\n        torch.save(model, dir + '/{}/{}_{}.pth'.format(model_name, model_name, k)) \n        model_all.append(model)\n    return model_all\n\nmodel_name = ['vgg16','vgg19','resnet101','resnet152','densenet161','densenet201'] \n\n# using densenet161 as our model\n# can experiment with other models\nmodel_all = auto_net(model_name[4], num_classes=3, use_pretrained=False, unfreeze_num=4)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:12:39.545497Z","iopub.execute_input":"2022-04-26T19:12:39.545870Z","iopub.status.idle":"2022-04-26T19:12:42.382726Z","shell.execute_reply.started":"2022-04-26T19:12:39.545837Z","shell.execute_reply":"2022-04-26T19:12:42.381855Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Data Preparation\n# Training dataframe\ntrain_df = pd.read_csv('../input/covidxct/train_COVIDx_CT-2A.txt', sep=\" \", header=None)\ntrain_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\ntrain_df=train_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )\n\n# Validation dataframe\nval_df = pd.read_csv('../input/covidxct/val_COVIDx_CT-2A.txt', sep=\" \", header=None)\nval_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\nval_df=val_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )\n\n# Testing dataframe\ntest_df = pd.read_csv('../input/covidxct/test_COVIDx_CT-2A.txt', sep=\" \", header=None)\ntest_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\ntest_df=test_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:12:53.233448Z","iopub.execute_input":"2022-04-26T19:12:53.233843Z","iopub.status.idle":"2022-04-26T19:12:53.538534Z","shell.execute_reply.started":"2022-04-26T19:12:53.233812Z","shell.execute_reply":"2022-04-26T19:12:53.537689Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"image_path = '../input/covidxct/2A_images/'  # directory path of images\ntrain_df['filename'] = image_path + train_df['filename']\nval_df['filename'] = image_path + val_df['filename']\ntest_df['filename'] = image_path + test_df['filename']\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:12:56.923394Z","iopub.execute_input":"2022-04-26T19:12:56.923793Z","iopub.status.idle":"2022-04-26T19:12:56.984929Z","shell.execute_reply.started":"2022-04-26T19:12:56.923762Z","shell.execute_reply":"2022-04-26T19:12:56.984012Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Checking for number of samples in different catogries\ntrain_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:12:56.633162Z","iopub.execute_input":"2022-04-26T19:12:56.633498Z","iopub.status.idle":"2022-04-26T19:12:56.647076Z","shell.execute_reply.started":"2022-04-26T19:12:56.633465Z","shell.execute_reply":"2022-04-26T19:12:56.646250Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Balancing the training and validation datastets \n# since number of samples in the 3 catogaries are quite different.\nN = train_df[train_df['label'] == 0]\nP = train_df[train_df['label'] == 1]\nC = train_df[train_df['label'] == 2]\n\nfrom sklearn.utils import resample\n\nN_download = resample(N, replace = True, n_samples = 25496, random_state=0)\nC_download = resample(C, replace = True, n_samples = 25496, random_state=0)\ntrain_df = pd.concat([N_download, P, C_download])\ntrain_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:12:57.810207Z","iopub.execute_input":"2022-04-26T19:12:57.810537Z","iopub.status.idle":"2022-04-26T19:12:57.839001Z","shell.execute_reply.started":"2022-04-26T19:12:57.810507Z","shell.execute_reply":"2022-04-26T19:12:57.838056Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"N_v = val_df[val_df['label'] == 0]\nP_v = val_df[val_df['label'] == 1]\nC_v = val_df[val_df['label'] == 2]\n\nfrom sklearn.utils import resample\n\nN_v_download = resample(N_v, replace = True, n_samples = 6244,random_state=0)\nP_v_download = resample(P_v, replace = True, n_samples = 6244,random_state=0)\nval_df = pd.concat([N_v_download, P_v_download, C_v])\n\nval_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:12:58.241120Z","iopub.execute_input":"2022-04-26T19:12:58.241427Z","iopub.status.idle":"2022-04-26T19:12:58.260205Z","shell.execute_reply.started":"2022-04-26T19:12:58.241399Z","shell.execute_reply":"2022-04-26T19:12:58.259455Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# shuffle the dataset\ntrain_df = shuffle(train_df) \nval_df = shuffle(val_df)\ntest_df = shuffle(test_df)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:12:58.590965Z","iopub.execute_input":"2022-04-26T19:12:58.591222Z","iopub.status.idle":"2022-04-26T19:12:58.618324Z","shell.execute_reply.started":"2022-04-26T19:12:58.591197Z","shell.execute_reply":"2022-04-26T19:12:58.616743Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"labels = {0:'Normal',1:'Pneumonia',2:'COVID-19'}\nclass_names = ['Normal','Pneumonia','COVID-19']\n\n# creating catogary column \ntrain_df['label_n'] = [labels[b] for b in train_df['label']]\nval_df['label_n'] = [labels[b] for b in val_df['label']]\ntest_df['label_n'] = [labels[b] for b in test_df['label']]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:12:59.106071Z","iopub.execute_input":"2022-04-26T19:12:59.106394Z","iopub.status.idle":"2022-04-26T19:12:59.149619Z","shell.execute_reply.started":"2022-04-26T19:12:59.106360Z","shell.execute_reply":"2022-04-26T19:12:59.148177Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(f\"Negative and positive values of train: \\n{train_df['label_n'].value_counts()}\")\nprint(f\"Negative and positive values of validation: \\n{val_df['label_n'].value_counts()}\")\nprint(f\"Negative and positive values of test: \\n{test_df['label_n'].value_counts()}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:12:59.565255Z","iopub.execute_input":"2022-04-26T19:12:59.565595Z","iopub.status.idle":"2022-04-26T19:12:59.598602Z","shell.execute_reply.started":"2022-04-26T19:12:59.565560Z","shell.execute_reply":"2022-04-26T19:12:59.597695Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_df=train_df.reset_index()\nval_df=val_df.reset_index()\ntest_df=test_df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:13:00.135126Z","iopub.execute_input":"2022-04-26T19:13:00.135452Z","iopub.status.idle":"2022-04-26T19:13:00.147793Z","shell.execute_reply.started":"2022-04-26T19:13:00.135420Z","shell.execute_reply":"2022-04-26T19:13:00.146774Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class CovidDataset(Dataset):\n    def __init__(self, dataset_df, transform=None):\n        self.dataset_df = dataset_df\n        self.transform = transform\n        \n    def __len__(self):\n        return self.dataset_df.shape[0]\n    \n    def __getitem__(self, idx):\n        image_name = self.dataset_df['filename'][idx]\n        img = Image.open(image_name)\n        label = self.dataset_df['label'][idx]\n        \n        if self.transform:\n            img = self.transform(img)\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:13:00.533491Z","iopub.execute_input":"2022-04-26T19:13:00.533807Z","iopub.status.idle":"2022-04-26T19:13:00.539349Z","shell.execute_reply.started":"2022-04-26T19:13:00.533779Z","shell.execute_reply":"2022-04-26T19:13:00.538534Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Training variables and hyperparamater\nbatch_size = 64\ninput_channel = 1\ninput_size = (224,224)\ncrop_size = (340,380)\nnum_classes = 3\nnum_epochs = 5","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:13:01.139982Z","iopub.execute_input":"2022-04-26T19:13:01.140288Z","iopub.status.idle":"2022-04-26T19:13:01.145656Z","shell.execute_reply.started":"2022-04-26T19:13:01.140259Z","shell.execute_reply":"2022-04-26T19:13:01.144571Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Image transformations \ntransform = {\n    'train':transforms.Compose([\n        transforms.RandomHorizontalFlip(p=0.5), # Image augmentations for training\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.RandomRotation(30),\n        transforms.CenterCrop(crop_size),\n        transforms.Resize(input_size),\n        transforms.Grayscale(input_channel),\n        transforms.ToTensor(),\n        transforms.Normalize([0.6349431],[0.32605055])\n    ]),\n    'test':transforms.Compose([\n        transforms.CenterCrop(crop_size),\n        transforms.Resize(input_size),\n        transforms.Grayscale(input_channel),\n        transforms.ToTensor(),\n        transforms.Normalize([0.63507175],[0.3278614])\n    ])\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:13:02.068169Z","iopub.execute_input":"2022-04-26T19:13:02.068489Z","iopub.status.idle":"2022-04-26T19:13:02.075059Z","shell.execute_reply.started":"2022-04-26T19:13:02.068458Z","shell.execute_reply":"2022-04-26T19:13:02.074195Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"dataset_names = ['train','val','test']\nimage_transforms = {'train':transform['train'], 'val':transform['test'],'test':transform['test']}\n\ntrain_dataset = CovidDataset(train_df, transform=image_transforms['train'])\nval_dataset = CovidDataset(val_df, transform=image_transforms['val'])\ntest_dataset = CovidDataset(test_df, transform=image_transforms['test'])\n\nimage_dataset = {'train':train_dataset, 'val':val_dataset,'test':test_dataset}\n\n# Intialzing DataLoader for Pytorch training and evaluation.\ndataloaders = {x:DataLoader(image_dataset[x],batch_size=batch_size,shuffle=True,num_workers=4) for x in dataset_names}\n\ndataset_sizes = {x:len(image_dataset[x]) for x in dataset_names}\n\nprint(dataset_sizes)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:13:02.708672Z","iopub.execute_input":"2022-04-26T19:13:02.709004Z","iopub.status.idle":"2022-04-26T19:13:02.716322Z","shell.execute_reply.started":"2022-04-26T19:13:02.708974Z","shell.execute_reply":"2022-04-26T19:13:02.715360Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\n\ndef show_tensor_img(tensor_img):\n    img=transforms.ToPILImage()(tensor_img)\n    plt.figure()\n    plt.imshow(img,plt.cm.gray)\n    plt.show()\n\n# Displaying some sample images from train dataset\nfor i in range(4):\n    show_tensor_img(train_dataset[i][0])","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:13:04.588396Z","iopub.execute_input":"2022-04-26T19:13:04.588747Z","iopub.status.idle":"2022-04-26T19:13:05.352154Z","shell.execute_reply.started":"2022-04-26T19:13:04.588716Z","shell.execute_reply":"2022-04-26T19:13:05.351345Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import itertools\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    cm=cm.numpy()\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        cm=cm.astype('int')\n        print('Confusion matrix, without normalization')\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    fmt = '{:.2f}' if normalize else '{}'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n      plt.text(i, j, fmt.format(cm[i, j]),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n\n\ndef confusion_matrix(preds, labels, conf_matrix):\n    preds = torch.argmax(preds, 1)\n    for p, t in zip(preds, labels):\n        conf_matrix[t, p] += 1\n    return conf_matrix\n\ndef calculate_all_prediction(conf_matrix):\n    total_sum = conf_matrix.sum()\n    correct_sum = (np.diag(conf_matrix)).sum()\n    prediction = round(100*float(correct_sum)/float(total_sum),2)\n    return prediction\n \ndef calculate_label_prediction(conf_matrix,labelidx):\n    label_total_sum = conf_matrix.sum(axis=0)[labelidx]\n    label_correct_sum = conf_matrix[labelidx][labelidx]\n    prediction = 0\n    if label_total_sum != 0:\n        prediction = round(100*float(label_correct_sum)/float(label_total_sum),2)\n    return prediction\n \ndef calculate_label_recall(conf_matrix,labelidx):\n    label_total_sum = conf_matrix.sum(axis=1)[labelidx]\n    label_correct_sum = conf_matrix[labelidx][labelidx]\n    recall = 0\n    if label_total_sum != 0:\n        recall = round(100*float(label_correct_sum)/float(label_total_sum),2)\n    return recall\n \ndef calculate_f1(prediction,recall):\n    if (prediction+recall)==0:\n        return 0\n    return round(2*prediction*recall/(prediction+recall),2)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:13:06.714997Z","iopub.execute_input":"2022-04-26T19:13:06.715320Z","iopub.status.idle":"2022-04-26T19:13:06.729627Z","shell.execute_reply.started":"2022-04-26T19:13:06.715290Z","shell.execute_reply":"2022-04-26T19:13:06.728647Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"pretrained_model_path = '../input/densetnet161/densenet161_3.pth'\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel_name = ['vgg16','vgg19','resnet101','resnet152','densenet161','densenet201'] \n\n# using densenet161 as our model\n# can experiment with other models\nmodel = torch.load(pretrained_model_path)\nmodel = model.to(device)\n\ncriterion=nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam( model.parameters(), lr=0.0001,betas=(0.9, 0.999))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-26T19:13:12.350655Z","iopub.execute_input":"2022-04-26T19:13:12.350984Z","iopub.status.idle":"2022-04-26T19:13:18.823820Z","shell.execute_reply.started":"2022-04-26T19:13:12.350955Z","shell.execute_reply":"2022-04-26T19:13:18.822936Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm # for progess bar\n\ndef train(model, epoch, num_epochs, criterion,optimizer):\n    model.train()\n    print('-' * 100)\n    #print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n    running_loss = 0.0\n    running_corrects = 0\n    with tqdm(dataloaders['train'], unit=\"batch\") as tepoch:\n        for idx, (inputs, labels) in enumerate(tepoch):\n            tepoch.set_description(f\"Epoch {epoch}\")\n\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs) \n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, labels) \n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            acc = torch.sum(preds == labels.data)/batch_size * 100.0\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n            tepoch.set_postfix(loss=loss.item(), acc = acc)\n\n    epoch_loss = running_loss / dataset_sizes['train']\n    epoch_acc = running_corrects.double() / dataset_sizes['train']\n    print('train_total Loss: {:.4f} Acc: {:.4f}%'.format( epoch_loss, epoch_acc*100))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:13:18.825291Z","iopub.execute_input":"2022-04-26T19:13:18.825624Z","iopub.status.idle":"2022-04-26T19:13:18.836106Z","shell.execute_reply.started":"2022-04-26T19:13:18.825583Z","shell.execute_reply":"2022-04-26T19:13:18.835170Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def validate(model,epoch,num_epochs,criterion,optimizer,best_acc):\n    model.eval()\n    running_loss = 0.0\n    running_corrects = 0\n    best_acc=best_acc\n    best_model_wts=copy.deepcopy(model.state_dict())\n    conf_matrix = torch.zeros(num_classes, num_classes) \n    with torch.no_grad():\n        for idx, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, labels)\n            conf_matrix = confusion_matrix(outputs, labels, conf_matrix) \n\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data) \n\n        plot_confusion_matrix(conf_matrix, classes=class_names, normalize=False, title='confusion matrix') \n\n    epoch_loss = running_loss / dataset_sizes['val'] \n    epoch_acc = running_corrects.double() / dataset_sizes['val'] \n    print('val_total Loss: {:.4f} Acc: {:.4f}%'.format( epoch_loss, epoch_acc*100))\n\n    all_prediction = calculate_all_prediction(conf_matrix) \n    print('all_prediction:{}'.format(all_prediction))\n    label_prediction = [] \n    label_recall = [] \n    for i in range(num_classes):\n        label_prediction.append(calculate_label_prediction(conf_matrix,i))\n        label_recall.append(calculate_label_recall(conf_matrix,i))\n\n    keys = class_names\n    values = list(range(num_classes))\n    dictionary = dict(zip(keys, values))\n    for ei, i in enumerate(dictionary):\n        print(ei,'\\t',i,'\\t','prediction=', label_prediction[ei],'%,\\trecall=',label_recall[ei],'%,\\tf1=',calculate_f1(label_prediction[ei],label_recall[ei])) # 输出每个类的，精确率，召回率，F1\n    p = round(np.array(label_prediction).sum()/len(label_prediction),2) \n    r = round(np.array(label_recall).sum()/len(label_prediction),2) \n    print('MACRO-averaged:\\nprediction=', p, '%,recall=', r, '%,f1=', calculate_f1(p,r)) \n\n    if epoch_acc > best_acc:\n        best_acc=epoch_acc.item()\n        best_model_wts=copy.deepcopy(model.state_dict())\n\n    return best_model_wts,best_acc,epoch_acc.item()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:13:18.838232Z","iopub.execute_input":"2022-04-26T19:13:18.838650Z","iopub.status.idle":"2022-04-26T19:13:18.852535Z","shell.execute_reply.started":"2022-04-26T19:13:18.838614Z","shell.execute_reply":"2022-04-26T19:13:18.851722Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import copy\n\nnum_epochs = 3\nbest_model_path = \"densenet201_3_model_best_acc.pth\"\n\nif __name__ == '__main__':\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    acc=[]\n    for epoch in range(num_epochs):\n        train(model,epoch,num_epochs,criterion,optimizer)\n        best_model_wts,best_acc,epoch_acc=validate(model, epoch, num_epochs, criterion, optimizer, best_acc)\n        acc.append(epoch_acc)\n    print('*' * 100)\n    print('best_acc:{}'.format(best_acc))\n    print('*' * 100)\n    torch.save(best_model_wts, best_model_path)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:13:23.004272Z","iopub.execute_input":"2022-04-26T19:13:23.004606Z","iopub.status.idle":"2022-04-26T19:45:54.373441Z","shell.execute_reply.started":"2022-04-26T19:13:23.004573Z","shell.execute_reply":"2022-04-26T19:45:54.371498Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"x=range(len(acc))\ny=acc\nplt.figure()\nplt.title('densenet161_3_acc_lr=0.0001')\nplt.plot(x,y)\nplt.savefig('mini64_lr0.0001_e20_densenet161_3_acc.jpg')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T20:11:47.937443Z","iopub.execute_input":"2022-04-26T20:11:47.937821Z","iopub.status.idle":"2022-04-26T20:11:48.104206Z","shell.execute_reply.started":"2022-04-26T20:11:47.937789Z","shell.execute_reply":"2022-04-26T20:11:48.103442Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Testing best accuracy model on our Test Set\n\n# incorrectly saved model name :\"densenet201...\" instead of \"densenet161\"\nbest_model_path =  \"./densenet201_3_model_best_acc.pth\" \n\nbest_model, input_size = initialize_model(\"densenet161\", 3, False, 3)\nbest_model.load_state_dict(torch.load(best_model_path))\nbest_model = best_model.to(device)\n\nprint(input_size)\n\ndef show_inference_result(tensor_img, ground_truth, predicted):\n    img=transforms.ToPILImage()(tensor_img)\n    plt.figure()\n    plt.imshow(img,plt.cm.gray)\n    plt.title(\"Ground Truth = {}, Predicted = {}\".format(ground_truth, predicted))\n    plt.show()\n\npredictions = []\nground_truths = []\nconf_matrix = torch.zeros(num_classes, num_classes) \n\nwith tqdm(dataloaders['test'], unit=\"batch\") as tepoch:\n        for idx, (inputs, labels) in enumerate(tepoch):\n            tepoch.set_description(f\"Testing \")\n            ground_truths.append(labels)\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs) \n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, labels) \n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            acc = torch.sum(preds == labels.data)/batch_size * 100.0\n            conf_matrix = confusion_matrix(outputs, labels, conf_matrix) \n            predictions.append(preds)\n\n            tepoch.set_postfix(acc = acc)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T20:32:56.252607Z","iopub.execute_input":"2022-04-26T20:32:56.253041Z","iopub.status.idle":"2022-04-26T20:35:23.369861Z","shell.execute_reply.started":"2022-04-26T20:32:56.253001Z","shell.execute_reply":"2022-04-26T20:35:23.368492Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(conf_matrix, classes=class_names, normalize=False, title='confusion matrix') \n\nall_prediction = calculate_all_prediction(conf_matrix) \nprint('all_prediction:{}'.format(all_prediction))\nlabel_prediction = [] \nlabel_recall = [] \nfor i in range(num_classes):\n    label_prediction.append(calculate_label_prediction(conf_matrix,i))\n    label_recall.append(calculate_label_recall(conf_matrix,i))\n\nkeys = class_names\nvalues = list(range(num_classes))\ndictionary = dict(zip(keys, values))\nfor ei, i in enumerate(dictionary):\n    print(ei,'\\t',i,'\\t','prediction=', label_prediction[ei],'%,\\trecall=',label_recall[ei],'%,\\tf1=',calculate_f1(label_prediction[ei],label_recall[ei])) # 输出每个类的，精确率，召回率，F1\np = round(np.array(label_prediction).sum()/len(label_prediction),2) \nr = round(np.array(label_recall).sum()/len(label_prediction),2) \nprint('MACRO-averaged:\\nprediction=', p, '%,recall=', r, '%,f1=', calculate_f1(p,r)) ","metadata":{"execution":{"iopub.status.busy":"2022-04-26T20:38:27.091922Z","iopub.execute_input":"2022-04-26T20:38:27.092332Z","iopub.status.idle":"2022-04-26T20:38:27.360020Z","shell.execute_reply.started":"2022-04-26T20:38:27.092290Z","shell.execute_reply":"2022-04-26T20:38:27.359223Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}